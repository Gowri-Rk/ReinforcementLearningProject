Overview
=====

Chess reinforcement learning by [AlphaGo Zero](https://deepmind.com/blog/alphago-zero-learning-scratch/) methods.

This project is based on these main resources:

1) DeepMind just released a new version of AlphaGo Zero (named now AlphaZero) where they master chess from scratch:
https://arxiv.org/pdf/1712.01815.pdf. 

2) DeepMind's Oct 19th publication: [Mastering the Game of Go without Human Knowledge](https://www.nature.com/articles/nature24270.epdf?author_access_token=VJXbVjaSHxFoctQQ4p2k4tRgN0jAjWel9jnR3ZoTv0PVW4gB86EEpGqTRDtpIz-2rmo8-KG06gqVobU5NSCFeHILHcVFUeMsbvwS-lxjqQGg98faovwjxeTUgZAUMnRQ).


3) Python implementation of AlphaGo Zero chess: https://github.com/Zeta36/chess-alpha-zero


## Setup

### Install libraries
```bash
pip install -r requirements.txt
```


## Usage

You will need to execute `Self-Play`, `Optimizer` and `Evaluator`.


### Self-Play

Self-Play will start using generate a model and play continously with itself.
If the model does not exist, new random model will be created.

```bash
python src/run.py --cmd self-play
```

### Optimizer

A base model will be loaded and trained from latest saved `generated_data/next-generation model`. If it doesn't exists, model generated by self play is used. Trained model will be saved every epoch.

```bash
python src/run.py --cmd optimize
```

Evaluator
---------
Plays self-play model and the latest next-generation model for some games. If next-generation model wins, it becomes current/self-play model.

```bash
python src/run.py --cmd evaluate
```
